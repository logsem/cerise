\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage{hyperref}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{mathpartir}
\usepackage{tensor}
\usepackage{xspace}
\usepackage[dvipsnames]{xcolor}
\usepackage{iris}
\usepackage{marvosym}
\usepackage{xargs}

\setlength{\parskip}{0.3em}

\newcommand{\Z}{\mathbb{Z}}
\newcommand{\X}[1]{\ensuremath{\mathrm{#1}}}
\newcommand{\V}[1]{\ensuremath{\mathit{#1}}}
\newcommand{\I}[1]{\ensuremath{\mathtt{#1}}}
\newcommand{\T}[1]{\texttt{#1}}
\newcommand{\SL}{Separation Logic\xspace}
\newcommand{\pure}[1]{\tensor[^{\ulcorner}]{#1{}}{^{\urcorner}}} %Hacky {} to avoid double superscript

\newcommand{\FIXME}[1]{{\color{MidnightBlue} FIXME: #1}}

\newcommand{\MMIO}{\textlog{MMIO}\xspace}

\DeclareMathOperator{\initOKo}{init_{OK}}
\newcommandx{\initOK}[3][2=r,3=m]{\initOKo(#1,#2,#3)}
\DeclareMathOperator{\initBCo}{init_{BC}}
\newcommandx{\initBC}[2][1=r,2=m]{\initBCo(#1,#2)}

\newcommand{\app}{\mathbin{+\!\!+}}

\newenvironment{remark}
{ \bigskip\hrule\vspace{-1.3em}\nobreak
  \paragraph*{Remark:}}
{\vspace*{0.5em}\hrule\medskip}

\title{Capabilities, MMIO and Robust Safety}
\date{March 10, 2020}

\begin{document}

\maketitle

\section{Memory Mapped I/O: Operational Semantics}

The proposal is to simply represent read and writes to memory-mapped IO
addresses as events in a trace. This says nothing a priori about devices that
might be connected to these IO regions. In particular, without additional
assumptions, reading a byte from a memory-mapped region just returns an
arbitrary value.

If at some point we want to reason under the assumption that we are connected to
a specific device that reacts in a specific way, we can express that as an extra
\SL assertion, that we assume as a pre-condition, and that restricts the set of
different traces that we might observe.

\[
  \begin{array}{lcl}
    \X{EventTy} & := & \X{IOWrite} \; | \; \X{IORead} \\
    \X{Event} & := & \X{EventTy} \times \X{Addr} \times \Z \\
    \X{Trace} & := & \X{list} \; \X{Event} \\
    \X{State} & := & \underbrace{\X{Reg} \times \X{Mem}}_{\text{old state}}
                     \times \X{Trace} \\
  \end{array}
\]

Values of type \X{State} represent the state of a configuration in the
small-step operational semantics. In this setup, we assume the whole semantics
to be parameterized by the range of memory-mapped addresses: \MMIO.

\[
  \begin{array}{lcl}
    \MMIO & := & [\MMIO_{\X{b}}, \MMIO_{\X{e}}) \\
  \end{array}
\]

In the (current) operational semantics without MMIO, the operational semantics
of the \I{Load} instruction is:

\begin{mathpar}
  \inferrule[Load]
  { r[\X{src}] = (p,g,b,e,a) \\ \X{readAllowed}\; p \\ a \in [b,e) }
  { (r, m) \xrightarrow{\I{Load} \; \X{dst} \; \X{src}} (r[\X{dst} := m[a]], m) }
\end{mathpar}

With MMIO, we obtain two rules for \I{Load}:

\begin{mathpar}
  \inferrule[MemLoad]
  { r[\X{src}] = (p,g,b,e,a) \\ \X{readAllowed}\; p \\ a \in [b,e) \\ a \notin \MMIO}
  { (r, m, t) \xrightarrow{\I{Load} \; \X{dst} \; \X{src}}
    (r[\X{dst} := m[a]], m, t) }

  \inferrule[IOLoad]
  { r[\X{src}] = (p,g,b,e,a) \\ \X{readAllowed}\; p \\ a \in [b,e) \\ a \in \MMIO}
  { (r, m, t) \xrightarrow{\I{Load} \; \X{dst} \; \X{src}}
    (r[\X{dst} := x], m, t \app (\X{IORead}, a, x)) }
\end{mathpar}

Notice how in the second rule, we read an arbitrary integer $x$, and record it
in the trace.

The \I{Store} rule would be similar.

Notice that, for any address in \MMIO, which value is held by the map $m$ as
that address is now irrelevant. Indeed, $m$ is never read nor modified for
addresses in \MMIO. One could choose to enforce that a particular dummy value is
stored in $m$ for these addresses. Instead, we choose to leave them
unconstrained.

\begin{remark}
  Thomas: Additionally, we might want to disallow in the semantics an execution
  with a \X{PC} register pointing to an $\MMIO$ location (I think this makes
  more sense than reading a random instruction through I/O). Armaël: but it
  makes the semantics of all instructions more complicated.
\end{remark}


\begin{remark} With this presentation, the specification of the
``machine'' is very much decoupled from the model of the devices it might be
communicating with. This is a good thing, I think.

Nevertheless, one could consider an alternative presentation where the model of
the devices is more tightly integrated with the semantics of the machine. For
instance, one could make the operational semantics parameterized with the
devices' model, where each device is modeled as having some internal state, the
ability to react on reads or writes, or to perform an internal step. Then, the
operational semantics would either step the usual way, or whenever a device
steps.

I believe this would be somewhat similar to the semantics of I/O system calls
through a foreign function interfaces as formalized in
CakeML~\cite{cakeml-vstte17io}, and also in Perennial~\cite{perennial-lang}.
%


\end{remark}

\begin{remark} Alix says that the proposed style of operational semantics
(using a trace) is close to the semantics of \texttt{volatile} as in
CompCert---which is also how memory mapped addresses seem to be exposed to C
compilers in practice. So this is probably a good sign. 
\end{remark}


\section{\SL Resources}

We added a trace as part of the state, so we wish to also expose it as a \SL
assertion. Recall the current definition of the state interpretation:
\[
  \X{state\_interp} \; (r,m) := \X{gen\_heap\_ctx}\; r \ast \X{gen\_heap\_ctx}\; m
\]


\newcommand{\tracefull}[1]{\ownGhost{\gamma_{\X{T}}}{\authfull{#1}}}
\newcommand{\tracefrag}[1]{\ownGhost{\gamma_{\X{T}}}{\authfrag{#1}}}

The simplest way to account for the trace is to directly expose it in a
monolithic fashion. In that case, the state interpretation additionally holds a
resource for the trace.
\[
  \X{state\_interp} \; (r,m,t) :=
    \X{gen\_heap\_ctx}\; r \ast
    \X{gen\_heap\_ctx}\; (m \setminus \MMIO) \ast
    {\color{BrickRed}\tracefull{t}}
\]

Note that we restrict the usual ``points-to'' assertions to be used only for
non-MMIO addresses. Instead, to assert ownership of the MMIO region, the user
works with assertions of the form $\tracefrag{t'}$. Such an assertion is not
duplicable, and grants full ownership over the trace. In particular, it allows
one to \emph{update} the trace by emitting events, i.e. by performing I/O
operations.

The wp-rules for \I{Load} and \I{Store} need to be updated consequently. For
instance, the rule for a \I{Load} reading the integer $x$ on a MMIO address $a$
now requires $\tracefrag{t}$ in the pre-condition (for some $t$), and provides
$\tracefrag{t \app (\X{IORead}, a, x)}$ in the post-condition.

The corresponding resource algebra is $\authm(\exm(\X{Trace}))$. A few relevant
rules are:

\[
  \begin{array}{l}
    \tracefull{t} \ast \tracefrag{t'} \wand \pure{t = t'} \\
    \tracefrag{t} \ast \tracefrag{t'} \wand \FALSE \\
    \tracefull{t} \ast \tracefrag{t} \vsW \tracefull{t'} \ast \tracefrag{t'} \\
  \end{array}
\]


\begin{remark} This is very coarse-grained: either one has the full
ownership for performing I/O and reasoning about it, or one cannot know anything
about it.

A first extension could be to allow observing prefixes of the trace (since
events can only be appended to the trace). The observation that the trace
has a given prefix would be duplicable. This again seems to be an application of
monotonicity, that could be realized by having a duplicable AtLeast part as part
of $\tracefrag{t'}$,
similarly to how we currently model Monotone References.

Another extension, that seems very useful for modular reasoning, would be to
allow splitting the trace along separate range of addresses. Concretely, a trace
containing events about the range of MMIO addresses $[a,c)$ could be split into
two traces, granting ownership over events on addresses $[a,b)$ and $[b,c)$
respectively. Note that recombining these two traces would only yield some
unspecified interleaving of the events from the two traces, and not necessarily
yield the original trace, since in our model, we cannot know the exact interleaving of IO operations issued by different parties.

One application of this second extension could be the verification of an example
involving ``multiplexed'' I/O, where two separate parts of the code are granted
separate ownership over separate MMIO addresses. These two separate pieces of
code would be verified separately; then, in the end, one could prove that one
gets \emph{some} interleaving of all the events emitted by both components.
\end{remark}

\newcommand{\MMIOag}{\ownGhost{\gamma_{\X{MMIO}}}{\authfull (\X{MMIO})}}

\begin{remark}
  As an alternative to having the set of MMIO addresses (\MMIO) as a global
  parameter, we might want to make it part of the state in the operational
  semantics. In that case, we would need another resource algebra to model the
  MMIO locations, i.e. add do the state interpretation we had before:
%
\[
  \X{state\_interp} \; (r,m,t,\MMIO) := \ldots \ast \MMIOag
\]

(where $\authm(\exm(\X{Trace}))$ is the resource algebra).
\end{remark}

\begin{remark}
In the future, we might be interested in the dynamic allocation of MMIO memory.
The question is what this would mean, though, since the set of available devices
allowing for MMIO access and the concrete buffers they provide will most likely
still be modeled as fixed at runtime.
Rather, this would allow us to take (un)mapped MMIO locations, connected to the different devices, and (un)map them anywhere in main memory.
This would require a different way of modeling MMIO, where we need both a notion
of the total pool of possible MMIO locations, and a description of the currently
mapped locations. We could model this using an authoritative RA.
\end{remark}

\section{Toplevel Theorem (\emph{à la} OCPL)}

Let us start with a brief recap of the toplevel ``Robust Safety'' theorem for
OCPL itself (and its key ingredients), then the extension (by Thomas) of OCPL to
include a \I{print} capability, and finally move to the capability machine
setting.

\subsection{OCPL}

The {\sc RobustSafety} theorem of OCPL is as follows:

\begin{mathpar}
  \mprset{vskip=0.3em}
  \inferrule
  {C \in \textit{AdvCtx} \\
    e \; \X{closed} \\
    \hoare{\TRUE}{e}{x.\; \textlog{lowval}\; x} \\
    (C[e]);(\emptyset, \textlog{OK}) \longrightarrow^* T';(h',g')
  }
  {g' = \textlog{OK}}
\end{mathpar}

For any closed expression $e$, if $e$ has been verified to only return low
values, then running $e$ wrapped in an adversarial context $C$ from an initial
state, then we can observe that every reachable state is good
($g' = \textlog{OK}$ means that no assertion has failed in $e$).

$C \in AdvCtx$ means that $C$ cannot contain assertions (otherwise one could
trivially contradict the theorem by taking
$C[\cdot] = \textlog{assert false}$), and cannot contain references to raw
memory locations (otherwise one could directly access $e$'s private state,
invalidating the local state encapsulation mechanisms).

\newcommand{\lift}[2]{\textlog{lift}\; #1 \; #2}
\newcommand{\liftP}[1]{\lift{\Psi}{#1}}

$\textlog{lowval}\; x$ intuitively means that $x$ cannot be used to directly
access private (or ``high'') locations. It is formally defined using a logical
relation ``$\liftP{v}$'', which more generally asserts that the value $v$ only
gives direct access to locations that satisfy the predicate $\Psi$.

\[
  \begin{array}{lcl}
    \liftP (\textlog{rec}\; f\; x.\; e) & \eqdef
    & \later \forall v.\; \hoare{\liftP{v}}{e[v/x,\textlog{rec}\;f\;x.\; e/f]}{y.\; \liftP y} \\
    %
    \liftP (v_{1}, v_{2}) & \eqdef & \later (\liftP v_{1}, \liftP v_{2}) \\
    %
    \color{BrickRed} \liftP \ell & \color{BrickRed} \eqdef & \color{BrickRed} \Psi \; \ell \\
    %
    \ldots
  \end{array}
\]

Then, $\textlog{lowval}\; x$ is defined as $\lift{\textlog{lowloc}}{x}$, where
$\textlog{lowloc}$ is a predicate characterizing the region of memory containing
``low locations'' (distinct from the other region containing ``high
locations'').

\subsection{OCPL with \I{print}}

\newcommand{\OutV}{\textlog{Out}}

In Thomas' extension of OCPL, a new value $\OutV$ is added, denoting an
``output object capability'', as well as a $\textlog{print}$ primitive, where
$\textlog{print}\; \OutV\; v$ effectively ``prints'' the value $v$, i.e. adds it
to the trace of printed values.

One then wants to be able to encapsulate the use of $\OutV$, for instance by
defining object capabilities that enforce some invariants on the values being
printed. In that setting, $\OutV$ is considered as a ``high'' value:
%
\[
  \begin{array}{lcl}
    \liftP \OutV & \eqdef & \FALSE
  \end{array}
\]

The theorem then becomes:
%
\begin{mathpar}
  \mprset{vskip=0.4em}
  \inferrule
  {C \in \textit{AdvCtx} \\
    e \; \X{closed} \\
    \knowInv{\iota}{\exists t.\; \tracefrag{t} \ast \pure{\! P(t)}} \vdash \hoare{\TRUE}{e}{x.\; \textlog{lowval}\; x} \\
    (C[e]);(\emptyset, \textlog{OK}); \emptyset \longrightarrow^* T';(h',g'); t
  }
  {g' = \textlog{OK} \wedge P(t)}
\end{mathpar}

That is, if $e$ has been verified under the assumption that the predicate $P$
holds as a trace invariant, then executing $e$ in an adversarial context yields
a trace that does satisfy $P$.

$C \in \textit{AdvCtx}$ also has to be extended to forbid $C$ from containing
$\OutV$.

\medskip

To be slightly more general, we could actually allow sharing $\OutV$ in case the
predicate $P$ does not place any constraints on the output, i.e. it is the
$\TRUE$ predicate. Technically, we could hence have the following alternative
definition for $\textlog{lift}$ (although admittedly, it does look a bit
hard-coded):
%
\[
  \begin{array}{lcl}
    \liftP \OutV & \eqdef & \exists \iota \ldotp \knowInv{\iota}{\exists t\ldotp \tracefrag{t} \ast
                            \pure{(\Lam{\_}.\TRUE) \spac t}}
  \end{array}
\]

\subsection{Capability Machine with MMIO}

\subsubsection{Logical relation}

\newcommand{\VR}{\mathcal{V}}
\newcommand{\ER}{\mathcal{E}}
\newcommand{\RR}{\mathcal{R}}
\newcommand{\notMMIO}{\overline{\MMIO}}

Similarly to $\textlog{lift}$, we can generalize the existing logical relation
to thread a constraint on directly accessible memory locations. One would
parameterize the value, expression and register relations ($\VR$, $\ER$ and $\RR$)
with a predicate $\Psi$ on addresses.

Then, for any permission $p$ that includes either the R or W bit, $\VR$
is extended as follows:

\[
  \VR^{\Psi}(p, g, b, e, a) \eqdef \underbrace{\ldots}_{\text{as before}} \ast \; \pure{\forall a' \in [b,e).\; \Psi(a')}
\]

Then, $\ER^{\Psi}$ and $\RR^{\Psi}$ are simplify defined by threading the extra
$\Psi$ parameter through the existing definition.

Finally, for our relation to characterize ``low values'' that do not give direct
access to MMIO addresses, one would instantiate $\Psi$ with a predicate
$\notMMIO$ that excludes memory mapped addresses:

\[
  \notMMIO(a) \eqdef a \notin \MMIO
\]

Then, $\VR^{\notMMIO}$ is similar to the $\textlog{lowval}$ predicate of OCPL.
Intuitively, a value in the relation does not directly point to memory-mapped
locations, nor can it gain access to memory-mapped locations indirectly,
similarly to how $\textlog{lowval}$s cannot grant access to high locations
directly. The relation $\ER^{\notMMIO}$ specifies that, if we fill the registers
with values in $\VR^{\notMMIO}$, then the invariants in a private future world
of our starting world will be satisfied at the end of execution.

\begin{remark} As it is defined above, the ``generalized'' value relation
is in fact not very useful for instantiation of $\Psi$ other than $\notMMIO$.
Indeed, even if $\Psi$ \emph{does} allow referring to addresses in the $\MMIO$
region, the value relation does not grant any corresponding resources. The fix
would be to use the generalized trace resources mentioned previously, and grant
ownership for the part of the trace corresponding to the addresses in
$[b,e) \cap \MMIO_{\X{pub}}$ with $\MMIO_{\X{pub}}$ the shareable subset of
addresses in \MMIO.
\end{remark}


\subsubsection{Robust safety theorem}

A first attempt at adapting the OCPL robust safety theorem to the capability
machine setting might look something like the following
{\color{BrickRed}\textbf{(incomplete!)}} statement.

\begin{mathpar}
  \mprset{vskip=0.5em}
  \inferrule
  { \forall a_{i} \in A_{\X{entry}} \ldotp\,
      \knowInv{\iota}{\exists t.\; \tracefrag{t} \ast P(t)}\!
         \vdash
         \forall W \ldotp\;(\ER^{\notMMIO} (\X{RX}, g, b, e, a_i))\spac W
       \\
     \\
    (r[\overline{r_{a_{i}} := (\X{E}, g, b, e, a_i)}], m, \emptyset) \longrightarrow^*
    (r', m', t)
  }
  {P(t)}
\end{mathpar}

The code that is verified (similar to the expression $e$ in OCPL) is here given
as a set of \emph{entrypoints} (addresses) $A_{\X{entry}}$.
%
The capability $(\X{RX}, g, b, e, a_i)$ then points to the $i$th entry point of
the code we want to gradually verify.

The capability $(\X{E}, g, b, e, a_i)$ then represents a closure for this same piece
of code. Adversarial code only gets access to the closure (as an enter
capability), in order to avoid them from executing or reading arbitrary lines of
code within the trusted module.

Notice the universal quantification over worlds in the precondition;
this needs to be there, since we do not know in what world our code will be
called.

\begin{remark}
  We could simplify the theorem statement by only considering the case of a
  single entrypoint. This is equivalent: a piece of code that wants to expose
  two distinct ``methods'' can implement a single toplevel entrypoint that
  immediately returns two pointers that can then be used to invoke the two
  methods.
  %
  This would make the toplevel theorem simpler, at the cost of somewhat more
  contrieved calling convention between trusted and untrusted code.
\end{remark}

\begin{remark}
The universal quantification on worlds was not explicitly present in the OCPL
formalization.
The reason for that is that (I think so at least, do not quote me
on this - Thomas) they
used the built-in Iris worlds within their definition of weakest precondition,
by leveraging the state interpretation, which is universally quantified over in
the definition of weakest precondition.
As we discussed before, if we do away
with local capabilities, it should be possible to fall back onto Iris' notion of
worlds, which would allow us to remove the universal quantification in the
above definition too because it would be implicitly present in the WP inside $\ER$.

It would be interesting to have a discussion about how to do away with the
worlds if we remove local capabilities, regardless of whether we will in the
end, since that might shed some light on why the worlds look the way they do
right now.
\end{remark}

\begin{remark}
  Note that we could have written
  $\ldots \vdash \forall W \ldotp \; (\VR^{\notMMIO} (\X{E}, \ldots))\; W$ %)
  in the above theorem, instead of using the expression relation. This is
  equivalent, and easily unfolds to the former statement through the definition
  of the value relation. I wrote $\ER$ to place the focus on the execution of
  the driver being safe. I consider this a matter of taste.
\end{remark}

\medskip

The theorem above is \emph{incomplete}. In other words, it is not provable as
is, because it includes no notion of adversarial context (similar to OCPL's
\textit{AdvCtx}), and therefore imposes no restriction on the adversarial code
(i.e., the contents of the $r$ and $m$ other than our verified code).
%
As such, the statement can be trivially falsified by taking an attacker with
direct read or write access to any location in \MMIO, or with direct access to
the trusted code's internal state.

We move to a theorem statement that correctly constrains the adversary in two
steps:
%
\begin{enumerate}
  \item We add a syntactic condition (on the state of memory and registers) to
    the tentative statement of our robust safety theorem, ensuring that the
    adversary code cannot gain access to any non-$\X{E}$ capabilities pointing into
    the driver code or any capabilities pointing into $\MMIO$ directly.
%
  \item Then, we provide an end-to-end statement that assumes the existence of a
    piece of boot code, that gets to run first when the capability machine
    starts up, and makes sure the above condition indeed holds before passing
    control to the adversary.

    The boot code is part of the trusted code base, and must satisfy a given
    specification, as a precondition of the toplevel theorem.

    The particular implementation of the boot code depends on the model of the
    initial state of the machine. If the memory can contain any capability at
    startup, then the boot code has to erase the memory before passing control.
    If we assume that the initial memory cannot contain any capabilities
    whatsoever, then the boot code does not need to do any cleanup.
\end{enumerate}

In this setting, we can subdivide the memory $m$ into 3 relevant subsections;
$m = m_{\MMIO} \uplus m_{\X{driver}} \uplus m_{\X{adv}}$ %\uplus m_{\X{frame}}
with the following meaning:
\begin{itemize}
\item $m_{\MMIO}$ contains the memory-mapped locations
\item $m_{\X{driver}}$ contains the driver code
\item  $m_{\X{adv}}$ contains the adversary's code and data (this will also
  include the boot code in the general setting, since it does not contain any
  inherently dangerous capabilities itself).
\end{itemize}

\newcommand{\nonCap}[1]{\ensuremath{\mathrm{nonCap}(#1)}}

We can then implement the syntactic check as requiring registers and memory to
only contain non-capability values:

\def \MathparLineskip {\lineskiplimit=0.7em\lineskip=0.7em}
\begin{mathpar}
  \nonCap{\X{inl}\; z} \eqdef \TRUE \and
  \nonCap{\X{inr}\; (p,g,b,e,a)} \eqdef \FALSE \and
  \nonCap{\V{reg}} \eqdef \forall r \in \dom(\V{reg}).\; \nonCap{\V{reg}(r)} \and
  \nonCap{\V{mem}} \eqdef \forall l \in \dom(\V{mem}).\; \nonCap{\V{mem}(l)}
\end{mathpar}

\newcommand{\notMapsToR}[2]{\rightarrow^{\overline{#1}}\!\!(#2)}

Given this definition, we can now formalize the initialization constraints on
registers $r$ and memory $m$, given the region $\MMIO$ and
the driver's address space $[b,e)$ as follows:

\begin{mathpar}
  \mprset{vskip=0.4em}
  \inferrule
  { m = m_{\MMIO} \uplus m_{\X{driver}} \uplus m_{\X{adv}}\\
    \dom( m_{\MMIO} ) = \MMIO \\
    \dom( m_{\X{driver}} ) = [b,e)\\
    \dom( m_{\X{adv}} ) = [b_{\X{adv}},e_{\X{adv}})\\
    \nonCap{\V{r}}\\
    \nonCap{\V{m_{\X{adv}}}} \\
    r[\X{PC}] = (\X{RWX}, \X{G},b_{\X{adv}},e_{\X{adv}},b_{\X{adv}})\\
  }
  {\initOK{[b,e)}}
\end{mathpar}


and subsequently formulate the robust safety theorem as follows:

\begin{mathpar}
  \mprset{vskip=0.5em}
  \inferrule
  { \forall a_{i} \in A_{\X{entry}} \ldotp\,
      \knowInv{\iota}{\exists t.\; \tracefrag{t} \ast P(t)}\!
         \vdash
         \forall W \ldotp\;(\ER^{\notMMIO} (\X{RX}, g, b, e, a_i))\spac W
         \\
   \initOK{[b,e)} \\
  (r[\overline{r_{a_{i}} := (\X{E}, g, b, e, a_i)}], m, \emptyset) \longrightarrow^* (r', m', t)\\
  }
  {P(t)}
\end{mathpar}

where we have set the PC up to be a sensible capability (pointing to
$b_{\X{adv}}$ without loss of generality).

Notice how the syntactic check for the registers is only performed on the set of registers $r$, allowing the closures in $\overline{r_{a_i}}$ to point into to the driver address space.

\begin{remark}
  If useful, the syntactic check can be relaxed to allow any capabilities that
  do not point into the MMIO region or the driver's memory. One would define the
  predicate $\notMapsToR{R}{w}$, that takes a word, memory region or register
  file and checks if it points into the forbidden region $R$ as follows:

\[
  \begin{array}{lcl}
    \notMapsToR{R}{\X{inl}\spac z} & \eqdef
    & \TRUE \\
    %
    \notMapsToR{R}{\X{inr}\spac (p,g,b,e,a)} & \eqdef & R \cap [b,e)\; =
                                                 \emptyset  \\
    %
    \notMapsToR{R}{\V{reg}} & \eqdef & \forall r \in \dom(\V{reg}) \ldotp\spac \notMapsToR{R}{\V{reg}(r)} \\
    %
    \notMapsToR{R}{\V{mem}} & \eqdef & \forall l \in \dom(\V{mem}) \ldotp\spac   \notMapsToR{R}{\V{mem}(l)}
  \end{array}
\]

Then, one would use $\notMapsToR{\MMIO \cup [b,e)}$ in place of $\nonCap{}$.
\end{remark}

Having this theorem in our toolbox, we can now take a closer look at scenario 2
above, where a piece of boot code is used to set the memory up correctly,
obviating the need for any other assumptions than that the boot code behaves
according to some spec. Concretely, we want the boot code to uphold a spec that
allows us to prove the above theorem.
%
(Alternatively, we could also just implement one specific instance of boot code,
and prove that after it finishes executing, all preconditions to apply the above
theorem are met.)

Let $r_0$ and $m_0$ be the respective initial state of registers and memory
immediately after booting. We assume that the following two properties hold,
where $l_\X{boot}$ is some memory location (initially loaded in PC):
%
\begin{mathpar}
  \dom(m_0) = [0,\X{MEM_{MAX}}) \and
  r_0[\X{PC}] = (\X{RWX}, \X{G},0,\X{MEM_{MAX}},l_{\X{boot}})
\end{mathpar}

Depending on the specifics of the operiational semantics, we might have more
information about $m_0$ and $r_0$, that can then be used in the implementation
of the boot code (e.g., $m_0$ might be initialized to only zeroes).

We also assume the boot-code to be initially loaded in memory at address
$l_{\X{boot}}$.
%
Then, the specification for the boot code that we have to prove is stated as
follows:

\newcommand{\bigast}[2]{\underset{#1}\Sep{\!\!\! #2}\;}

\[
  \begin{array}{l}
  \X{bootSpec}(P, g, b, e, A_{\X{entry}}) \eqdef {} \\[0.8em]
    \quad
  \begin{array}{l}
    \left\{
    \begin{array}{l}
      \X{PC} \mapsto_{r} (\X{RWX}, \X{G}, 0, \X{MEM_{MAX}}, l_{\X{boot}}) \ast {} \\[0.5em]
      \bigast{r \in \X{Reg} \setminus \X{PC}}{r \mapsto_{r} \_}
      \ast \bigast{m \in \X{Mem} \setminus \MMIO}{m \mapsto_{a} \_}
      \ast \tracefrag{\emptyset}
    \end{array}
    \right\}
    \\[2em]
    \quad \I{Instr}\; \I{Executable}
    \\[0.5em]
    \left\{
    \begin{array}{l}
      \exists b_{adv}\; e_{adv}\; t.\; \\[0.5em]
      \quad
      \begin{array}{l}
        \X{PC} \mapsto_{r} (\X{RWX}, \X{G}, b_{adv}, e_{adv}, b_{adv}) \ast {} \\[0.7em]
        \bigast{a_{i} \in A_{\X{entry}}}{a_{i} \mapsto_{r} (\X{E},g,b,e,a_i)} \ast
        \bigast{r \in Reg\setminus \{\X{PC}, A_{\X{entry}}\}}{r \mapsto_{r} \X{inl}\; \_} \ast {} \\[1.4em]
        \bigast{m \in [b_{adv}, e_{adv})}{m \mapsto_{a} \X{inl}\; \_} \ast
        \bigast{m \in [b, e)}{m \mapsto_{a} \_} \ast
        \; \tracefrag{t} \ast \pure{P(t)}
      \end{array}
    \end{array}
    \right\}
  \end{array}
  \end{array}
\]

Intuitively, establishing this specification ensures that, after running the
boot code, we arrive in a state that satisfies $\initOKo$.

The resulting boot-code-base formulation of the robust safety theorem is now a
corollary of the general robust safety theorem, and has the following statement:

\begin{mathpar}
  \mprset{vskip=0.5em}
  \inferrule
  { \forall a_{i} \in A_{\X{entry}} \ldotp\,
      \knowInv{\iota}{\exists t.\; \tracefrag{t} \ast P(t)}\!
         \vdash
         \forall W \ldotp\;(\ER^{\notMMIO} (\X{RX}, g, b, e, a_i))\spac W
         \\
   \X{bootSpec}(P,g,b,e,A_{\X{entry}}) \\
  (r_0, m_0, \emptyset) \longrightarrow^* (r, m, t)\\
  }
  {P(t)}
\end{mathpar}

Note that to link scenario 2 to scenario 1, we need a slightly adapted version
of the robust safety theorem stated previously, where the initial trace is
allowed to not be empty, but rather just satisfy $P(t)$, but that should not
cause any problems.

Note as well that if the boot-code performs I/O, then it is required to preserve
the invariant $P$ on the trace. If needed, one could come up with a more general
theorem statement, where the boot code is allowed to perform arbitrary I/O, and
where $P$ is thus only true of the suffix of the trace for events that occur
\emph{after} the boot code has run...

\begin{remark}
  On the level of the operational semantics, proving the boot specification
  corresponds to proving that the following holds, in order to use our concrete
  driver implementation with the robust safety theorem above (the driver still
  needs to be proven safe separately):
\[
  \begin{array}{l}
    (\textsc {BootCodeOK}) \\[0.5em]
%
    \exists n\; b\; e\ldotp (r_0, m_0, \emptyset) \longrightarrow^n (r'[\overline{r_{a_{i}}
    := (\X{E}, g, b, e, a_i)}], m', t) \\[0.5em]
    {} \land P(t) \land \initOK{[b,e)}[r'][m']
  \end{array}
\]
\end{remark}

\subsubsection{Concrete boot and driver code}

Now we have a closer look at the concrete example we would like to verify,
including what its boot code looks like. Our goal is to prove that this concrete
example satisfies \X{bootSpec} (alternatively, \textsc{BootCodeOk}) and this
last robust safety theorem.

The code for for the driver scenario we want to gradually verify can
be found in \T{driver\_code.v}. This example file contains more details on the
scenario in the comments. From a more high-level perspective, it contains a
trusted part, consisting of a single MMIO location, boot code to properly set up
the capability machine at start-up, and the code for the driver itself. On the
other hand, the example also contains an untrusted part, consisting of a known,
but untrusted code section and sandbox section (which we do not make assumptions
over).
The first address of the adversary code section is what the trusted part jumps
to once it has finished setting up.

The boot code is where execution starts off when the capability machine is
powered on.
It contains an omnipotent RWX capability (i.e. ranging over all of memory and
providing full permissions over it) starts off execution.
(\textbf{Design Alternative:} in the long run, it might be worthwhile to provide
the boot code with a RWLX capability. Since RWX cannot be upgraded to RWLX, it
is impossible in the current setting to develop a secure stack calling
convention \'a la Lau, where the stack capability has to be local-WL and (in this
case) the driver code has to ensure that there is no other WL than the stack.
However, having a global stack capability is currently not an issue, since the interface to our driver is first order, i.e. it will
never create another adversary stack frame on top of itself (currently, it does
not even use the stack in the first place!), and since we are working in a
single-threaded setting (not very relevant, but I think the multi-threaded
setting is an interesting thought experiment). I avoided unnecessary
complications and hence kept the omnipotent capability as RWX. If the omnipotent
capability were to become RWLX in the future, we would have to be careful using
a stack, since if we want our secure calling convention with a higher order
interface to our driver API, there cannot be any adversary-accessible global
write-local memory, i.e. the reduced omnipotent capability cannot be allowed to be global if we pass it to the adversary. We would thus have to pass a stack capability that we explicitly make local, and a global RWX capability for the rest of memory)

The boot code has the following responsibilities:
\begin{itemize}
  \item Generate the necessary closures (i.e. Enter capabilities) for the
    driver's read and write methods, so that the adversary can use safely use
    them to perform I/O, and any properties that the driver wants to uphold on
    the input-output stream can actually be enforced.
%
  \item Wipe all of the adversary's sandbox section, to make sure no remaining
  capabilities can be found there.
  %
    (\textbf{Design Alternative:} maybe we should try to find out how CHERI
    handles this; is it possible that any lingering capabilities are left in RAM
    on machine start-up? In any case, we are already being slightly unrealistic
    by assuming the adversary code section is just \emph{there}. We have the
    option to not do any erasure, and just make the assumption that adversary
    memory contains no capabilities pointing into MMIO or pointing into the
    driver.).
  %
    It does not, however, wipe the untrusted, hard-coded adversary routine that
    reads $N$ lines of code from a single (and the only) MMIO location in
    memory.
%
  \item Reduce the omnipotent capability to provide RWX access to all of the
    adversary's code, makes it point to the first element of the adversary's
    code section and jumps to it, in order to hand control to the adversary.
    Before the jump, it clears all registers except for the 2 containing the
    read and write driver closures, in order to make sure that no extra
    permissions leak to the adversary.
\end{itemize}

\bibliographystyle{alpha}
\bibliography{biblio}

\appendix

\end{document}
